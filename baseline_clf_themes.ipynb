{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, hamming_loss, zero_one_loss, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THEMES = [5, 6, 26, 33, 139, 163, 232, 313, 339, 350, 406, 409, 555, 589,\n",
    "          597, 634, 660, 695, 729, 766, 773, 793, 800, 810, 852, 895, 951, 975]\n",
    "TRAIN_DATA_PATH = '../train.csv'\n",
    "TEST_DATA_PATH = '../test.csv'\n",
    "VALIDATION_DATA_PATH = '../validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_process(df):\n",
    "    new_df = df.sort_values(['process_id', 'page'])\n",
    "    new_df = new_df.groupby(\n",
    "                ['process_id', 'themes'],\n",
    "                group_keys=False\n",
    "            ).apply(lambda x: x.body.str.cat(sep=' ')).reset_index()\n",
    "    new_df = new_df.rename(index=str, columns={0: \"body\"})\n",
    "    return new_df\n",
    "\n",
    "def get_data(path, preds=None, key=None):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.rename(columns={ 'pages': 'page'})\n",
    "    data = groupby_process(data)\n",
    "    data.themes = data.themes.apply(lambda x: literal_eval(x))\n",
    "    return data\n",
    "\n",
    "def transform_y(train_labels, test_labels):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(train_labels)\n",
    "\n",
    "    mlb_train = mlb.transform(train_labels)\n",
    "    mlb_test = mlb.transform(test_labels)\n",
    "\n",
    "    print(mlb.classes_)\n",
    "\n",
    "    return mlb_train, mlb_test, mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(TRAIN_DATA_PATH)\n",
    "test_data = get_data(TEST_DATA_PATH)\n",
    "validation_data = get_data(VALIDATION_DATA_PATH)\n",
    "\n",
    "train_data.themes = train_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "test_data.themes = test_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "validation_data.themes = validation_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "\n",
    "y_train, y_test, mlb = transform_y(train_data.themes, test_data.themes)\n",
    "\n",
    "X_train = train_data.body\n",
    "X_test = test_data.body\n",
    "print('X_train: {}, \\n\\ty_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test: {}, \\n\\ty_test: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Classes: ', mlb.classes_)\n",
    "print('We\\'re classifying {} themes!'.format(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "pipe_nb = Pipeline((\n",
    "    (\"vectorizer\", TfidfVectorizer(ngram_range=(1, 1), sublinear_tf=True,\n",
    "                                   min_df=0.1, max_features=10000)),\n",
    "    (\"clf\", OneVsRestClassifier(MultinomialNB(alpha=0.001, fit_prior=True), n_jobs=-1))\n",
    "))\n",
    "\n",
    "pipe_svc = Pipeline((\n",
    "    (\"vectorizer\", TfidfVectorizer(ngram_range=(1, 1), sublinear_tf=True,\n",
    "                                   min_df=0.1, max_features=10000)),\n",
    "    (\"clf\", OneVsRestClassifier(LinearSVC(verbose=2, class_weight=\"balanced\"), n_jobs=-1))\n",
    "))\n",
    "\n",
    "# parameters_vectorizer = {\n",
    "#     \"vectorizer__ngram_range\": [(1, 2)],\n",
    "#     \"vectorizer__sublinear_tf\": [True],\n",
    "#     \"vectorizer__min_df\": [1, 2, 3],\n",
    "#     \"vectorizer__max_df\": [0.5, 0.8, 1.]\n",
    "# }\n",
    "\n",
    "# parametersSVC = {\n",
    "#         \"clf__penalty\": [\"l2\"],\n",
    "#         \"clf__C\": [0.03, 1, 3, 10],\n",
    "#         \"clf__class_weight\": [\"balanced\"]\n",
    "# }\n",
    "\n",
    "# parametersSVC.update(parameters_vectorizer)\n",
    "\n",
    "# parametersNB = {\n",
    "#     \"clf__alpha\": [0.0001, 0.0003, 0.001],\n",
    "#     \"clf__fit_prior\": [True]\n",
    "# }\n",
    "\n",
    "# parametersNB.update(parameters_vectorizer)\n",
    "\n",
    "# parametersBoost = {\n",
    "#     \"clf__max_depth\": [3, 4, 5],\n",
    "#     \"clf__learning_rate\": [0.03, 0.1, 0.3],\n",
    "#     \"clf__n_estimators\": [100, 300, 1000, 3000]\n",
    "# }\n",
    "\n",
    "# parametersBoost.update(parameters_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# experiment, _, experiment_labels, _ = train_test_split(x_valid, y_valid, test_size=0.98, random_state=42,\n",
    "#                                                        stratify=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = GridSearchCV(estimator=pipe_svc, param_grid=parametersSVC, verbose=10, n_jobs=15, scoring=\"f1_macro\")\n",
    "# clf.fit(experiment, experiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.best_params_)\n",
    "# clf.best_score_\n",
    "# pipe_svc = clf.best_estimator_\n",
    "\n",
    "pipe_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[str(x) for x in mlb.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pipe_svc.predict(X_test)\n",
    "print(classification_report(y_test, preds_test, target_names=target_names, digits=4))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = GridSearchCV(estimator=pipe_nb, param_grid=parametersNB, verbose=10, n_jobs=15, scoring=\"f1_macro\")\n",
    "# clf.fit(experiment, experiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.best_params_)\n",
    "# clf.best_score_\n",
    "# pipe_nb = clf.best_estimator_\n",
    "\n",
    "pipe_nb.fit(X_train, y_joblib.dump(pipe_nb, './models/nb_clf_themes_medium.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pipe_nb.predict(X_test)\n",
    "print(classification_report(y_test, preds_test, target_names=target_names, digits=4))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(pipe_nb, './models/nb_clf_themes_medium.pkl')\n",
    "joblib.dump(pipe_svc, './models/svc_clf_themes_medium.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../train_parts_19-03-2019_small.csv'\n",
    "TEST_DATA_PATH = '../test_parts_19-03-2019_small.csv'\n",
    "VALIDATION_DATA_PATH = '../validation_parts_19-03-2019_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(TRAIN_DATA_PATH)\n",
    "test_data = get_data(TEST_DATA_PATH)\n",
    "validation_data = get_data(VALIDATION_DATA_PATH)\n",
    "\n",
    "train_data.themes = train_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "test_data.themes = test_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "validation_data.themes = validation_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "\n",
    "y_train, y_test, mlb = transform_y(train_data.themes, test_data.themes)\n",
    "\n",
    "X_train = train_data.body\n",
    "X_test = test_data.body\n",
    "print('X_train: {}, \\n\\ty_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test: {}, \\n\\ty_test: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Classes: ', mlb.classes_)\n",
    "print('We\\'re classifying {} themes!'.format(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[str(x) for x in mlb.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pipe_svc.predict(X_test)\n",
    "print(classification_report(y_test, preds_test, target_names=target_names, digits=4))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pipe_nb.predict(X_test)\n",
    "print(classification_report(y_test, preds_test, target_names=target_names, digits=4))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe_nb, './models/nb_clf_themes_small.pkl')\n",
    "joblib.dump(pipe_svc, './models/svc_clf_themes_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "with open(\"./models/svc_clf_themes_small.pkl\", \"rb\") as file:\n",
    "    model = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_words_for_tag(classifier, tag, tags_classes, index_to_words):\n",
    "    print('Tag:\\\\t{}'.format(tag))\n",
    "    # Extract an estimator from the classifier for the given tag.\\n\",\n",
    "    # Extract feature coefficients from the estimator. \\n\",\n",
    "    coefs = classifier.coef_[tags_classes.index(tag)]\n",
    "    sortedWords = [(index_to_words[x], coef) for coef,x in sorted(zip(coefs, range(len(coefs))))]\n",
    "    top_positive_words = sortedWords[:-10:-1]\n",
    "    top_negative_words = sortedWords[:10]\n",
    "#     top_positive_words = # top-5 words sorted by the coefficiens.\\n\",\n",
    "#     top_negative_words = # bottom-5 words  sorted by the coefficients.\\n\",\n",
    "    print('Top positive words:\\\\t{}'.format(top_positive_words))\n",
    "    print('Top negative words:\\\\t{}\\\\n'.format(top_negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model.steps[1][1]\n",
    "tfidf = model.steps[0][1]\n",
    "print_words_for_tag(clf, 729, mlb.classes_.tolist(), {i:word for word,i in tfidf.vocabulary_.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
